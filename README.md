# House Price Prediction using Linear Regression

A complete end-to-end Machine Learning project that predicts house prices using the Boston Housing Dataset.
This project covers data preprocessing, exploratory data analysis (EDA), model building, evaluation, and optimization using advanced regression techniques.
Problem Statement
The objective of this project is to predict the median value of owner-occupied homes (MEDV) based on several explanatory variables such as crime rate, number of rooms, property tax rate, proximity to the Charles River, and more.
Using the Boston Housing dataset, the project aims to:
‚Ä¢	Understand relationships between housing attributes and prices
‚Ä¢	Build a predictive model using Linear Regression
‚Ä¢	Evaluate and optimize model performance
‚Ä¢	Compare Linear Regression with Polynomial, Ridge, and Lasso models
Dataset
Boston Housing Dataset
Key features include:
‚Ä¢	crim: Per capita crime rate
‚Ä¢	rm: Average number of rooms
‚Ä¢	lstat: % of lower-status population
‚Ä¢	tax: Property tax rate
‚Ä¢	chas: Charles River dummy variable (1 = yes, 0 = no)
‚Ä¢	medv: Median home value (target variable)

Project Workflow
1. Data Collection & Loading
‚Ä¢	Load the CSV dataset into a pandas DataFrame
‚Ä¢	View structure, shape, and summary statistics
‚Ä¢	Identify missing values and inconsistencies

2. Data Preprocessing
‚Ä¢	Handle missing values
‚Ä¢	Encode categorical variables (e.g., CHAS)
‚Ä¢	Normalize/scale numerical features using StandardScaler
‚Ä¢	Split dataset into train and test sets

3. Exploratory Data Analysis (EDA)
Visualize important relationships such as:
‚Ä¢	Price vs. Rooms (RM)
‚Ä¢	Price vs. LSTAT
‚Ä¢	Price vs. CHAS
‚Ä¢	Correlation Heatmap
‚Ä¢	Distribution plots and boxplots
‚Ä¢	Scatterplots to observe linearity
Insights:
‚úî Prices increase with number of rooms
‚úî Prices decrease with higher LSTAT
‚úî Strong negative correlation between LSTAT and MEDV
‚úî RM is one of the strongest positive predictors

4. Model Building
Implement multiple regression models:
‚Ä¢	Linear Regression (baseline model)
‚Ä¢	Fit using training data
‚Ä¢	Predict house prices for unseen test data

5. Model Evaluation
Evaluate model performance using:
‚Ä¢	Mean Absolute Error (MAE)
‚Ä¢	Mean Squared Error (MSE)
‚Ä¢	R¬≤ Score
Plots:
‚Ä¢	Actual vs Predicted Price scatter plot

6. Model Optimization 
Experiment with improved models:
‚Ä¢	Polynomial Regression (degree 2 and above)
‚Ä¢	Ridge Regression (L2 regularization)
‚Ä¢	Lasso Regression (L1 regularization / feature selection)
Conduct hyperparameter tuning (alpha selection) and compare:
‚Ä¢	MAE
‚Ä¢	MSE
‚Ä¢	R¬≤ Score
Conclusion:
Polynomial Regression usually improves predictive accuracy and Ridge and Lasso help control overfitting and handle multicollinearity.

7. Saving the Model
Save trained model for deployment:
joblib.dump(model, "linear_regression_model.pkl")

 Results Summary
‚Ä¢	Linear Regression creates a simple, interpretable model
‚Ä¢	Polynomial Regression captures non-linear patterns, improving accuracy
‚Ä¢	Ridge & Lasso offer regularization benefits
‚Ä¢	Best model depends on the balance between accuracy and interpretability

Project Files
‚Ä¢	Project_2_House_Price_Prediction_using_Linear_Regression.ipynb
‚Ä¢	BostonHousing.csv 
‚Ä¢	linear_regression_model.pkl (saved model)
‚Ä¢	README.md 
‚Ä¢	Project Report
Key Takeaways
‚Ä¢	Learned the complete workflow of a supervised ML project
‚Ä¢	Understood how to clean and preprocess real-world data
‚Ä¢	Improved skills in visualization and feature analysis
‚Ä¢	Built and evaluated a regression model using scikit-learn
‚Ä¢	Explored advanced techniques such as Ridge, Lasso, and Polynomial Regression
‚Ä¢	Strengthened understanding of how numerical features influence house prices


House Price Prediction using Linear Regression

A complete end-to-end Machine Learning project that predicts house prices using the Boston Housing Dataset.
This project includes data preprocessing, exploratory data analysis (EDA), model building, model evaluation, and optimization using advanced regression techniques.

üìå Problem Statement

The goal of this project is to predict the median value of owner-occupied homes (MEDV) using features such as:

Crime rate

Number of rooms

Property tax rate

Proximity to the Charles River

% lower-status population

And more

The project aims to:

Understand relationships between housing attributes and price

Build a predictive model using Linear Regression

Evaluate and optimize model performance

Compare Linear Regression with Ridge, Lasso, and Polynomial Regression

üìä Dataset: Boston Housing

Key features:

Feature	Meaning
crim	Per capita crime rate
rm	Average number of rooms per dwelling
lstat	% of lower-status population
tax	Property tax rate
chas	Charles River dummy variable (1 = yes, 0 = no)
medv	Median home value (Target)
üîÑ Project Workflow
1. Data Collection & Loading

Load dataset using pandas

Inspect structure, shape, and summary statistics

Identify missing values

2. Data Preprocessing

Handle missing values

Encode categorical variables (e.g., chas)

Normalize/scale numeric features using StandardScaler

Split dataset into train and test sets

3. Exploratory Data Analysis (EDA)

Visualizations include:

MEDV vs RM

MEDV vs LSTAT

Boxplots and distribution plots

Correlation heatmap

Scatterplots for linearity

Key Insights:

‚úî Prices increase with number of rooms

‚úî Prices decrease with higher LSTAT

‚úî Strong negative correlation between LSTAT and MEDV

‚úî RM is one of the strongest positive predictors

4. Model Building

Implemented models:

Linear Regression (baseline)

Trained using the training set

Predictions generated for test set

5. Model Evaluation

Metrics used:

MAE (Mean Absolute Error)

MSE (Mean Squared Error)

R¬≤ Score

Visualization:

Actual vs Predicted scatter plot

6. Model Optimization

Techniques applied:

Polynomial Regression (degree 2+)

Ridge Regression (L2 regularization)

Lasso Regression (L1 regularization with feature selection)

Hyperparameter tuning for alpha values:

Compare MAE, MSE, R¬≤

Polynomial Regression often yields better performance

Ridge & Lasso help reduce overfitting

7. Saving the Model
joblib.dump(model, "linear_regression_model.pkl")

üìà Results Summary

Linear Regression gives an interpretable baseline model

Polynomial Regression captures non-linear patterns

Ridge and Lasso help with regularization and feature selection

Best model depends on accuracy vs interpretability trade-off

üìÅ Project Structure
‚îú‚îÄ‚îÄ Project_2_House_Price_Prediction_using_Linear_Regression.ipynb
‚îú‚îÄ‚îÄ BostonHousing.csv
‚îú‚îÄ‚îÄ linear_regression_model.pkl
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ Project Report

üéØ Key Takeaways

Learned complete ML project workflow

Improved understanding of preprocessing & feature scaling

Gained experience in EDA and visualization

Built and evaluated regression models

Explored Polynomial, Ridge, and Lasso Regression

Understood how numerical features influence house prices
